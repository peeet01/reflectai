import streamlit as st
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics import mutual_info_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import plotly.graph_objects as go

# ğŸ”§ Mutual information becslÃ©s (javÃ­tott)
def compute_mutual_info(x, y):
    x_binned = pd.qcut(x, q=10, duplicates='drop').cat.codes
    return mutual_info_score(x_binned, y)

# ğŸ¯ Information Bottleneck vesztesÃ©gfÃ¼ggvÃ©ny
def information_bottleneck_loss(I_xt, I_ty, beta):
    return I_xt - beta * I_ty

# ğŸ” IB-szimulÃ¡ciÃ³ rejtett zajjal
def simulate_ib(X, Y, beta, epochs=10, latent_dim=2):
    I_xt_list = []
    I_ty_list = []
    latent_history = []

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    for epoch in range(epochs):
        noise = np.random.normal(0, 1, X_scaled.shape)
        Z = X_scaled + beta * noise
        model = LogisticRegression(max_iter=1000)
        model.fit(Z, Y)
        preds = model.predict(Z)

        I_xt = compute_mutual_info(Z[:, 0], X_scaled[:, 0])
        I_ty = compute_mutual_info(Z[:, 0], preds)

        I_xt_list.append(I_xt)
        I_ty_list.append(I_ty)
        latent_history.append(Z)

    return I_xt_list, I_ty_list, latent_history

# ğŸ“ˆ 3D vizualizÃ¡ciÃ³ (t-SNE)
def visualize_3d(latent_data, Y, step):
    tsne = TSNE(n_components=3, perplexity=30, learning_rate='auto', init='pca')
    coords = tsne.fit_transform(latent_data[step])
    x, y, z = coords[:, 0], coords[:, 1], coords[:, 2]
    fig = go.Figure(data=[go.Scatter3d(
        x=x, y=y, z=z,
        mode='markers',
        marker=dict(size=5, color=Y, colorscale='Viridis', opacity=0.8)
    )])
    fig.update_layout(scene=dict(
        xaxis_title="t-SNE 1", yaxis_title="t-SNE 2", zaxis_title="t-SNE 3"
    ), margin=dict(l=0, r=0, t=30, b=0))
    return fig

# ğŸš€ Streamlit modul
def run():
    st.title("ğŸ” Information Bottleneck â€“ InformÃ¡ciÃ³s reprezentÃ¡ciÃ³k tÃ¶mÃ¶rÃ­tÃ©se")

    # ğŸ“˜ BevezetÅ‘
    st.markdown("""
    A *Information Bottleneck* (IB) elmÃ©let cÃ©lja, hogy egy bemeneti vÃ¡ltozÃ³t **minimÃ¡lis informÃ¡ciÃ³vesztesÃ©ggel tÃ¶mÃ¶rÃ­tsÃ¼nk**,  
    mikÃ¶zben megÅ‘rizzÃ¼k a lehetÅ‘ legtÃ¶bb informÃ¡ciÃ³t a **kimeneti cÃ©lvÃ¡ltozÃ³rÃ³l**.  
    A megkÃ¶zelÃ­tÃ©s egyszerre szolgÃ¡l **adatkompressziÃ³s** Ã©s **prediktÃ­v tanulÃ¡si** cÃ©lokat.

    Ez a modul interaktÃ­v mÃ³don vizualizÃ¡lja, hogyan vÃ¡ltozik a rejtett reprezentÃ¡ciÃ³ **informatÃ­v Ã©s kompakt formÃ¡ja**,  
    ahogy a **kompressziÃ³â€“pontossÃ¡g arÃ¡nyÃ¡t szabÃ¡lyozÃ³ Î²** paramÃ©ter vÃ¡ltozik.
    """)

    # âš™ï¸ ParamÃ©terek
    st.sidebar.header("âš™ï¸ ParamÃ©terek")
    beta = st.sidebar.slider("KompressziÃ³â€“relevancia sÃºly (Î²)", 0.01, 5.0, 1.0, step=0.05)
    latent_dim = st.sidebar.slider("Rejtett dimenziÃ³", 2, 10, 3)
    steps = st.sidebar.slider("Epoch-ok szÃ¡ma", 1, 20, 10)
    step_idx = st.sidebar.slider("VizualizÃ¡lt lÃ©pÃ©s", 0, steps - 1, 0)

    # ğŸ“Š AdatgenerÃ¡lÃ¡s (szintetikus osztÃ¡lyozÃ¡si feladat)
    from sklearn.datasets import make_classification
    X, Y = make_classification(n_samples=300, n_features=5, n_informative=3, n_classes=3, random_state=42)

    I_xt_list, I_ty_list, latent_history = simulate_ib(X, Y, beta, steps, latent_dim)

    # ğŸ“ˆ Mutual Information grafikon
    st.subheader("ğŸ“ˆ InformÃ¡ciÃ³s mennyisÃ©gek alakulÃ¡sa")
    df_info = pd.DataFrame({
        "Epoch": np.arange(steps),
        "I(X;T)": I_xt_list,
        "I(T;Y)": I_ty_list
    })
    st.line_chart(df_info.set_index("Epoch"))

    # ğŸŒ t-SNE 3D vizualizÃ¡ciÃ³
    st.subheader("ğŸŒ Rejtett reprezentÃ¡ciÃ³ â€“ 3D t-SNE")
    fig = visualize_3d(latent_history, Y, step_idx)
    st.plotly_chart(fig, use_container_width=True)

    # ğŸ’¾ CSV export
    st.subheader("ğŸ’¾ Latens reprezentÃ¡ciÃ³ export")
    df_latent = pd.DataFrame(latent_history[step_idx])
    df_latent["label"] = Y
    st.dataframe(df_latent)
    csv = df_latent.to_csv(index=False).encode("utf-8")
    st.download_button("â¬‡ï¸ CSV letÃ¶ltÃ©se", csv, "information_bottleneck_latent.csv", "text/csv")

    # ğŸ§  TudomÃ¡nyos hÃ¡ttÃ©r
    st.markdown("### ğŸ§  TudomÃ¡nyos hÃ¡ttÃ©r")
    st.latex(r"""
    \mathcal{L}_{IB} = I(X;T) - \beta \cdot I(T;Y)
    """)
    st.markdown("""
    - **\(X\)**: bemenet  
    - **\(T\)**: tÃ¶mÃ¶rÃ­tett (rejtett) reprezentÃ¡ciÃ³  
    - **\(Y\)**: cÃ©lvÃ¡ltozÃ³  
    - **\(I(A;B)\)**: mutual information A Ã©s B kÃ¶zÃ¶tt  
    - **Î²**: szabÃ¡lyozza az informÃ¡ciÃ³megÅ‘rzÃ©s Ã©s tÃ¶mÃ¶rÃ­tÃ©s arÃ¡nyÃ¡t

    A cÃ©l: megtalÃ¡lni olyan \(T\)-t, amely **minÃ©l tÃ¶bbet megtart \(Y\)-rÃ³l**,  
    mikÃ¶zben **minÃ©l kevesebb informÃ¡ciÃ³t tartalmaz \(X\)-bÅ‘l** â€“ azaz csak a lÃ©nyeges jellemzÅ‘ket.

    **KapcsolÃ³dÃ³ terÃ¼letek:** representation learning, variational inference, deep IB, unsupervised pretraining, AI fairness.
    """)

# âœ… ReflectAI kompatibilitÃ¡s
app = run
