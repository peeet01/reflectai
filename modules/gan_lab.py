# --- ğŸ“¦ KÃ¶nyvtÃ¡rak importÃ¡lÃ¡sa ---
import streamlit as st


import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torchvision.utils import make_grid
import matplotlib.pyplot as plt
import pandas as pd

# --- ğŸ¯ GenerÃ¡tor ---
class Generator(nn.Module):
    def __init__(self, z_dim=100, img_dim=28*28):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(z_dim, 256),
            nn.ReLU(True),
            nn.Linear(256, 512),
            nn.ReLU(True),
            nn.Linear(512, img_dim),
            nn.Tanh()
        )

    def forward(self, x):
        return self.net(x)

# --- âŒ DiszkriminÃ¡tor ---
class Discriminator(nn.Module):
    def __init__(self, img_dim=28*28):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(img_dim, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.net(x)

# --- ğŸ–¼ï¸ KÃ©pmegjelenÃ­tÅ‘ ---
def show_generated_images(generator, z_dim, device):
    generator.eval()
    with torch.no_grad():
        z = torch.randn(16, z_dim).to(device)
        fake_imgs = generator(z).view(-1, 1, 28, 28).cpu()
        grid = make_grid(fake_imgs, nrow=4, normalize=True)
        fig, ax = plt.subplots(figsize=(4, 4))
        ax.imshow(grid.permute(1, 2, 0))
        ax.axis("off")
        st.pyplot(fig)

# --- ğŸš€ GAN App ---
def run():
    st.title("ğŸ§  GAN Lab â€“ Generative Adversarial Network")

    st.markdown(r"""
A **GAN** egy generatÃ­v modell, amelyben kÃ©t neurÃ¡lis hÃ¡lÃ³zat â€“ a **GenerÃ¡tor** Ã©s a **DiszkriminÃ¡tor** â€“ verseng egymÃ¡ssal:

- A generÃ¡tor cÃ©lja, hogy valÃ³sÃ¡ghÅ± adatokat generÃ¡ljon:
  \[
  G(z) \rightarrow \hat{x}
  \]

- A diszkriminÃ¡tor cÃ©lja, hogy eldÃ¶ntse, az adat valÃ³s ($x$) vagy hamis ($\hat{x}$):
  \[
  D(x) \in [0, 1]
  \]

A cÃ©l: a generÃ¡tor megtanul olyan adatokat generÃ¡lni, amit a diszkriminÃ¡tor nem tud megkÃ¼lÃ¶nbÃ¶ztetni a valÃ³ditÃ³l.
""")

    device = "cuda" if torch.cuda.is_available() else "cpu"

    # --- âš™ï¸ ParamÃ©terek ---
    st.sidebar.header("ğŸ› ï¸ ParamÃ©terek")
    z_dim = st.sidebar.slider("Z dimenziÃ³", 64, 256, 100, step=16)
    lr = st.sidebar.select_slider("TanulÃ¡si rÃ¡ta", options=[1e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3], value=2e-4)
    epochs = st.sidebar.slider("Epochok", 1, 30, 5)
    batch_size = st.sidebar.slider("Batch mÃ©ret", 32, 256, 128, step=32)
    seed = st.sidebar.number_input("Seed", 0, 9999, 42)

    if st.button("ğŸ§ª TanÃ­tÃ¡s indÃ­tÃ¡sa"):
        torch.manual_seed(seed)

        # ğŸ“¥ Adatok
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))
        ])
        dataset = datasets.MNIST(root="./data", train=True, download=True, transform=transform)
        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

        # ğŸ§  HÃ¡lÃ³k
        generator = Generator(z_dim).to(device)
        discriminator = Discriminator().to(device)

        optim_g = optim.Adam(generator.parameters(), lr=lr)
        optim_d = optim.Adam(discriminator.parameters(), lr=lr)
        criterion = nn.BCELoss()

        g_losses, d_losses = [], []

        # ğŸ” TanÃ­tÃ¡s
        for epoch in range(epochs):
            for real_imgs, _ in loader:
                real_imgs = real_imgs.view(-1, 28*28).to(device)
                batch = real_imgs.size(0)
                real = torch.ones(batch, 1).to(device)
                fake = torch.zeros(batch, 1).to(device)

                # DiszkriminÃ¡tor
                z = torch.randn(batch, z_dim).to(device)
                fake_imgs = generator(z)
                loss_real = criterion(discriminator(real_imgs), real)
                loss_fake = criterion(discriminator(fake_imgs.detach()), fake)
                loss_d = (loss_real + loss_fake) / 2
                optim_d.zero_grad()
                loss_d.backward()
                optim_d.step()

                # GenerÃ¡tor
                z = torch.randn(batch, z_dim).to(device)
                fake_imgs = generator(z)
                loss_g = criterion(discriminator(fake_imgs), real)
                optim_g.zero_grad()
                loss_g.backward()
                optim_g.step()

            g_losses.append(loss_g.item())
            d_losses.append(loss_d.item())
            st.text(f"Epoch {epoch+1}/{epochs} | G: {loss_g.item():.4f} | D: {loss_d.item():.4f}")

        # ğŸ“ˆ Loss-gÃ¶rbÃ©k
        st.subheader("ğŸ“‰ VesztesÃ©ggÃ¶rbÃ©k")
        fig, ax = plt.subplots()
        ax.plot(g_losses, label="GenerÃ¡tor")
        ax.plot(d_losses, label="DiszkriminÃ¡tor")
        ax.set_xlabel("Epoch")
        ax.set_ylabel("Loss")
        ax.legend()
        st.pyplot(fig)

        # ğŸ–¼ï¸ MintÃ¡k
        st.subheader("ğŸ–¼ï¸ GenerÃ¡lt mintÃ¡k")
        show_generated_images(generator, z_dim, device)

        # ğŸ“ CSV export
        z = torch.randn(100, z_dim).to(device)
        samples = generator(z).view(-1, 28*28).cpu().detach().numpy()
        df = pd.DataFrame(samples)
        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button("â¬‡ï¸ MintÃ¡k letÃ¶ltÃ©se CSV-ben", data=csv, file_name="gan_samples.csv")

        # ğŸ“š TudomÃ¡nyos hÃ¡ttÃ©r
        st.markdown("### ğŸ“š TudomÃ¡nyos hÃ¡ttÃ©r")
        st.latex(r"""
        \min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}}[\log D(x)] + 
        \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))]
        """)
        st.markdown("""
A GAN modell egy min-max jÃ¡tÃ©kot jÃ¡tszik:
- A **generÃ¡tor** minimalizÃ¡lja a diszkriminÃ¡tor sikeressÃ©gÃ©t
- A **diszkriminÃ¡tor** maximalizÃ¡lja a sajÃ¡t osztÃ¡lyozÃ¡si pontossÃ¡gÃ¡t

Ez a versengÃ©s vezet el a reÃ¡lis, megtanult eloszlÃ¡sÃº mintÃ¡khoz.
""")

# ğŸ“ KÃ¶telezÅ‘ export
app = run
