import streamlit as st

def run():
    st.title("‚ùì Tudom√°nyos S√∫g√≥ ‚Äì Neurolab AI")
    st.markdown("""
    √údv√∂zl√ºnk a **Neurolab AI Scientific Playground** fel√ºleten!  
    Ez az alkalmaz√°s k√ºl√∂nf√©le elm√©leti √©s gyakorlati idegrendszeri, fizikai √©s matematikai modellek interakt√≠v vizsg√°lat√°t t√°mogatja.

    Az al√°bbiakban bemutatjuk az egyes modulok **matematikai alapjait**, **c√©lj√°t**, √©s **k√∂vetkeztet√©seit**.
    """)

    with st.expander("üï∏Ô∏è Kuramoto Modell ‚Äì Szinkroniz√°ci√≥s Dinamika"):
        st.latex(r"\frac{d\theta_i}{dt} = \omega_i + \frac{K}{N} \sum_{j=1}^{N} A_{ij} \sin(\theta_j - \theta_i)")
        st.markdown("""
        **Kollekt√≠v viselked√©s:** Egyedi oszcill√°torok f√°zisszinkroniz√°ci√≥j√°t √≠rja le.  
        Order parameter:
        """)
        st.latex(r"R(t) = \left| \frac{1}{N} \sum_{j=1}^{N} e^{i\theta_j(t)} \right|")
        st.markdown("""
        **C√©l:** Modellezi a neuronh√°l√≥zatok kollekt√≠v √°llapotait.  
        **Felhaszn√°l√°s:**
        - H√°l√≥zati instabilit√°sok detekt√°l√°sa  
        - Szinkron idegi aktivit√°s jellemz√©se  
        - Ritmikus zavarok (pl. epilepszia) szimul√°ci√≥ja  
        """)
        
    with st.expander("üß† Hebbian Learning ‚Äì Szinaptikus er≈ës√≠t√©s elve"):
        st.latex(r"\Delta w_{ij} = \eta \cdot x_i \cdot y_j")
        st.markdown("""
        **C√©l:** A tanul√°s sor√°n meger≈ës√≠teni azokat a kapcsolatokat, amelyek gyakran aktiv√°l√≥dnak egy√ºtt.

        **Magyar√°zat:**
        - $x_i$: preszinaptikus neuron aktivit√°sa  
        - $y_j$: posztszinaptikus neuron aktivit√°sa  
        - $\\eta$: tanul√°si r√°ta  
        - $\\Delta w_{ij}$: a szinaptikus s√∫ly m√≥dosul√°sa az $i \\to j$ kapcsolaton

        **Alapelve:**  
        ‚Äû**Neurons that fire together, wire together**‚Äù ‚Äì az egy√ºtt aktiv√°l√≥d√≥ neuronok k√∂z√∂tti kapcsolat er≈ës√∂dik.

        **Jellemz≈ëk:**
        - Egyszer≈±, biol√≥giailag inspir√°lt szab√°ly  
        - Nincs k√ºls≈ë tan√°ri jel (nem fel√ºgyelt tanul√°s)  
        - A tanul√°s **pozit√≠v visszacsatol√°st** eredm√©nyez

        **Felhaszn√°l√°s:**
        - Mint√°k tanul√°sa √©s reprezent√°ci√≥ja  
        - Alapja a k√©s≈ëbbi komplex tanul√°si szab√°lyoknak (pl. STDP, Oja, BCM)

        **Megjegyz√©s:**  
        A tiszta Hebbian tanul√°s instabil lehet ‚Äì gyakran **normaliz√°ci√≥val** eg√©sz√≠tik ki (pl. Oja szab√°ly).
        """)

    with st.expander("üí° Insight Learning ‚Äì Bel√°t√°sos tanul√°s szimul√°ci√≥"):
        st.markdown(r"""
        **C√©l:** Egy probl√©ma hirtelen, struktur√°lt megold√°s√°nak megtal√°l√°sa k√≠s√©rleti vagy vizu√°lis mint√°k alapj√°n.

        **Elm√©leti h√°tt√©r:**
        - Az **insight** nem fokozatos tanul√°son alapul, hanem hirtelen meg√©rt√©sen.
        - Nem sz√ºks√©ges folyamatos meger≈ës√≠t√©s vagy hibajel ‚Äì gyakran **struktur√°lis reprezent√°ci√≥k √°tszervez√©s√©b≈ël** sz√ºletik a megold√°s.
        - A viselked√©s ugr√°sszer≈±en javul, nem fokozatosan.

        **Anal√≥gia ‚Äì probl√©mat√©r √°trendez√©se:**
        $$ \text{Meg√©rt√©s: } \quad S_0 \xrightarrow{\text{transzform√°ci√≥}} S^* $$
        ahol:
        - $S_0$: kezdeti ment√°lis reprezent√°ci√≥  
        - $S^*$: √∫j strukt√∫ra, amely lehet≈ëv√© teszi a megold√°st

        **Felhaszn√°l√°s:**
        - Viselked√©spszichol√≥gia (K√∂hler, Gestalt-pszichol√≥gia)  
        - G√©pi tanul√°sban: strat√©giai √∫jratervez√©s, probl√©mamegold√°s mint√°zatb√≥l  
        - Robotik√°ban: **hirtelen √∫tvonaltervez√©s** vizu√°lis mint√°k alapj√°n

        **P√©lda:** Egy algoritmus nem a pr√≥b√°lkoz√°sok sz√°m√°val tanul, hanem a bemenet strukt√∫r√°j√°nak elemz√©s√©vel k√©pes felismerni az optim√°lis l√©p√©st.

        """)

    with st.expander("üå™Ô∏è Lorenz-rendszer ‚Äì MLP predikci√≥"):
        st.markdown("""
        **C√©l:** A Lorenz-rendszer egyik komponens√©nek (pl. \( x(t) \)) el≈ërejelz√©se **t√∂bbr√©teg≈± perceptron (MLP)** seg√≠ts√©g√©vel, kiz√°r√≥lag m√∫ltbeli adatok alapj√°n.
        """)

        st.markdown("**Lorenz-egyenletek:**")
        st.latex(r"\frac{dx}{dt} = \sigma(y - x)")
        st.latex(r"\frac{dy}{dt} = x(\rho - z) - y")
        st.latex(r"\frac{dz}{dt} = xy - \beta z")
        st.markdown(r"Ahol \( \sigma, \rho, \beta \) a rendszer param√©terei.")

        st.markdown("**MLP c√©lf√ºggv√©ny:**")
        st.latex(r"\hat{x}_{t+1} = f(x_t, x_{t-1}, \dots, x_{t-w})")

        st.markdown("""
        A modell megtanulja az id≈ësor **nemline√°ris dinamik√°j√°t** egy cs√∫sz√≥ ablakos megk√∂zel√≠t√©ssel.

        **Tanul√°s:**
        - Bemenet: \( w \) hossz√∫ m√∫ltbeli szakasz  
        - Kimenet: a k√∂vetkez≈ë id≈ël√©p√©s komponense (pl. \( x_{t+1} \))  
        - Loss: √°tlagos n√©gyzetes hiba (MSE)

        **Teljes√≠tm√©nymutat√≥k:**
        - \( R^2 \): a predikci√≥ magyar√°zati ereje  
        - MSE: a hib√°k √°tlagos n√©gyzete

        **Felhaszn√°l√°s:**
        - Determinisztikus k√°osz el≈ërejelz√©se  
        - Id≈ësoros predikci√≥ √©s nemline√°ris rendszerek elemz√©se  
        - G√©pi tanul√°si modellek tesztel√©se ismeretlen dinamik√°n
        """)
        
    with st.expander("üß† Hebbian Learning Viz ‚Äì Szinaptikus er≈ës√∂d√©s szeml√©ltet√©se"):
        st.latex(r"\Delta w = \eta \cdot x \cdot y")
        st.latex(r"x: \text{ bemeneti neuron aktivit√°sa}")
        st.latex(r"y: \text{ kimeneti neuron aktivit√°sa}")
        st.latex(r"\eta: \text{ tanul√°si r√°ta}")
        st.latex(r"\Delta w: \text{ szinaptikus s√∫lyv√°ltoz√°s}")

        st.markdown("""
        **C√©l:** A Hebbian tanul√°s bemutat√°sa vizu√°lisan, ahol a bemenet ($x$) √©s a kimenet ($y$) egy√ºttes aktivit√°sa meger≈ës√≠ti a szinaptikus kapcsolatot ($w$).  

        **Magyar√°zat:**  
        Ez a szab√°ly a h√≠res *"Cells that fire together, wire together"* elv√©t k√∂veti.  
        A modul vizu√°lisan mutatja be, hogy a gyakori egy√ºttes aktiv√°ci√≥ hogyan n√∂veli a kapcsolatok er≈ëss√©g√©t.

        **Alkalmaz√°s:**
        - Neur√°lis adapt√°ci√≥k vizsg√°lata  
        - Biol√≥giai tanul√°si folyamatok meg√©rt√©se  
        - Dinamikus h√°l√≥zati s√∫lym√≥dosul√°sok elemz√©se

        **Tudom√°nyos h√°tt√©r:**  
        A Hebbian tanul√°s egy alapvet≈ë **unsupervised learning** mechanizmus, amely a korrel√°lt aktivit√°st prefer√°lja, √©s a **neur√°lis reprezent√°ci√≥k kialakul√°s√°t** modellezi.
        """)

    with st.expander("üß† Oja Learning ‚Äì F≈ëkomponens tanul√°sa"):
        st.markdown(r"""
        **C√©l:** A modell megtanulja a bemenet legfontosabb ir√°ny√°t, azaz a **f≈ëkomponenst** (PCA-hasonl√≥ tanul√°s).

        **Tanul√°si szab√°ly:**
        """)
        st.latex(r"\Delta \mathbf{w} = \eta \cdot y \cdot (\mathbf{x} - y \cdot \mathbf{w})")
        st.markdown(r"""
        Ahol:  
        - $\mathbf{x}$: bemeneti vektor  
        - $\mathbf{w}$: s√∫lyvektor  
        - $y = \mathbf{w}^T \mathbf{x}$: neuron kimenete  
        - $\eta$: tanul√°si r√°ta  
        - $\Delta \mathbf{w}$: s√∫lyv√°ltoz√°s

        **Mechanizmus:**  
        Az Oja-szab√°ly a **Hebbian tanul√°st** eg√©sz√≠ti ki egy normaliz√°l√≥ taggal, √≠gy stabiliz√°lja a s√∫lyok n√∂veked√©s√©t.

        **Viselked√©s:**
        - A s√∫lyvektor konverg√°l a legnagyobb saj√°t√©rt√©khez tartoz√≥ saj√°tvektor ir√°ny√°ba  
        - Hasonl√≥an viselkedik, mint a PCA els≈ë komponense

        **Felhaszn√°l√°s:**  
        - Dimenzi√≥cs√∂kkent√©s neur√°lis √∫ton  
        - F≈ëkomponens detekci√≥ tanul√°s √∫tj√°n  
        - Nem fel√ºgyelt tanul√°si folyamatok modellez√©se  
        """)

    with st.expander("‚ùå XOR Predikci√≥ ‚Äì Neur√°lis h√°l√≥zat"):
        st.latex(r"\hat{y} = \sigma(W^{(2)} \cdot \sigma(W^{(1)}x + b^{(1)}) + b^{(2)})")
        st.latex(r"\mathcal{L} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2")
        st.markdown("""
        **C√©l:** A nemline√°risan szepar√°lhat√≥ probl√©m√°k (pl. XOR) rejtett r√©tegekkel oldhat√≥k meg.  
        **Felhaszn√°l√°s:**
        - M√©ly tanul√°si architekt√∫r√°k motiv√°ci√≥ja  
        - Line√°ris modellek korl√°tainak bemutat√°sa  
        """)

    with st.expander("‚è±Ô∏è STDP ‚Äì Spike-Timing Dependent Plasticity"):
        st.markdown("**C√©l:** A szinaptikus s√∫lyok id≈ëz√≠t√©salap√∫ m√≥dos√≠t√°sa ‚Äì biol√≥giailag inspir√°lt tanul√°si szab√°ly.")

        st.markdown("**Tanul√°si szab√°ly:**")
        st.latex(r"""
        \Delta w(\Delta t) =
        \begin{cases}
        A_+ \cdot e^{-\Delta t / \tau_+}, & \text{ha } \Delta t > 0 \ (\text{LTP}) \\\\
        -A_- \cdot e^{\Delta t / \tau_-}, & \text{ha } \Delta t < 0 \ (\text{LTD})
        \end{cases}
        """)

        st.markdown("**Ahol:**")
        st.markdown("""
        - \( \Delta t = t_{\text{post}} - t_{\text{pre}} \): a poszt- √©s preszinaptikus spike-ok k√∂z√∂tti id≈ëeltol√≥d√°s  
        - \( A_+, A_- \): a s√∫lyv√°ltoz√°s maxim√°lis amplit√∫d√≥i  
        - \( \tau_+, \tau_- \): id≈ë√°lland√≥k LTP-re √©s LTD-re k√ºl√∂n-k√ºl√∂n  
        - \( \Delta w \): a szinaptikus s√∫lyv√°ltoz√°s
        """)

        st.markdown("**Magyar√°zat:**")
        st.markdown("""
        - Ha a **preszinaptikus** neuron t√ºzel *a posztszinaptikus el≈ëtt* ( \( \Delta t > 0 \) ), akkor **Long-Term Potentiation** (LTP) t√∂rt√©nik ‚Üí er≈ës√∂dik a kapcsolat  
        - Ha a **preszinaptikus** neuron k√©s≈ëbb t√ºzel ( \( \Delta t < 0 \) ), akkor **Long-Term Depression** (LTD) t√∂rt√©nik ‚Üí gyeng√ºl a kapcsolat  
        - A v√°ltoz√°s m√©rt√©ke exponenci√°lisan cs√∂kken az id≈ëeltol√≥d√°s nagys√°g√°val
        """)

        st.markdown("**Alkalmaz√°s:**")
        st.markdown("""
        - Id≈ëz√≠t√©salap√∫ mintafelismer√©s tanul√°sa  
        - Biol√≥giailag hiteles neur√°lis modellek fejleszt√©se  
        - Nem fel√ºgyelt tanul√°s idegh√°l√≥zatokban  
        - Hebbian-elv tov√°bbfejlesztett, id≈ëz√≠tett v√°ltozata
        """)

    with st.expander("üß† Memory Landscape ‚Äì Asszociat√≠v t√°rol√°si t√©rk√©p"):
        st.latex(r"E(\mathbf{s}) = -\frac{1}{2} \sum_{i \neq j} W_{ij} s_i s_j")
        st.markdown("""
        **C√©l:** A neur√°lis h√°l√≥zat mem√≥riastrukt√∫r√°inak vizu√°lis felt√©rk√©pez√©se az energiaf√ºggv√©ny alapj√°n.  

        **Magyar√°zat:**
        - $E(\\mathbf{s})$: az adott √°llapothoz tartoz√≥ h√°l√≥zati energia  
        - $W_{ij}$: szinaptikus s√∫lym√°trix elemei  
        - $s_i$: az $i$-edik neuron √°llapota ($\\pm1$)  

        **Felhaszn√°l√°s:**
        - Mint√°k stabilit√°s√°nak √©s robusztuss√°g√°nak vizsg√°lata  
        - Lok√°lis minimumok detekt√°l√°sa az energiafel√ºleten  
        - Asszociat√≠v mem√≥ria t√©rk√©pez√©se (pl. Hopfield-h√°l√≥)

        **Tudom√°nyos h√°tt√©r:**  
        A mem√≥riat√°rol√°s √∫gy t√∂rt√©nik, hogy a mint√°khoz **energia-minimumok** rendel≈ëdnek. A h√°l√≥zat dinamika szerint ezekbe a minimumokba **konverg√°l**:
        """)
        st.latex(r"s_i^{(t+1)} = \mathrm{sign} \left( \sum_j W_{ij} s_j^{(t)} \right)")
        
    with st.expander("üåê Berry-g√∂rb√ºlet ‚Äì Kvantum topol√≥gia"):
        st.latex(r"\Omega(\mathbf{k}) = \nabla_{\mathbf{k}} \times \mathbf{A}(\mathbf{k}) \quad \text{ahol} \quad \mathbf{A}(\mathbf{k}) = -i \langle u(\mathbf{k}) | \nabla_{\mathbf{k}} | u(\mathbf{k}) \rangle")
        st.markdown("""
        **C√©l:** Kvant√°lt topol√≥giai mennyis√©gek megjelen√≠t√©se.  
        **Felhaszn√°l√°s:**
        - Kvantum Hall-effektus modellez√©se  
        - Topol√≥giai k√ºl√∂nbs√©gek azonos√≠t√°sa  
        """)

    with st.expander("üß† Hopfield-h√°l√≥ ‚Äì Asszociat√≠v mem√≥ria"):
        st.latex(r"W_{ij} = \sum_{\mu=1}^{P} \xi_i^\mu \xi_j^\mu")
        st.latex(r"s_i^{t+1} = \mathrm{sign} \left( \sum_j W_{ij} s_j^t \right)")
        st.markdown("""
        **C√©l:** Mint√°k visszakeres√©se zajos √°llapotb√≥l.  
        **Felhaszn√°l√°s:**
        - Mem√≥ria√°llapotok visszanyer√©se  
        - Energia-alap√∫ tanul√°si dinamika  
        """)

    with st.expander("üßÆ Fractal Dimension ‚Äì √ñn-szimil√°ris szerkezetek"):
        st.latex(r"D = \lim_{\epsilon \to 0} \frac{\log N(\epsilon)}{\log (1/\epsilon)}")
        st.markdown("""
        **C√©l:** A frakt√°ldimenzi√≥ a klasszikus dimenzi√≥ √°ltal√°nos√≠t√°sa, amely azt m√©ri, hogy egy objektum **mennyire t√∂lti ki a teret** k√ºl√∂nb√∂z≈ë sk√°l√°kon.  
        A fenti k√©plet a **box-counting dimenzi√≥** k√©plete, ahol:
        - $N(\\epsilon)$: az objektum lefed√©s√©hez sz√ºks√©ges $\epsilon$ m√©ret≈± dobozok sz√°ma  
        - $\epsilon$: a doboz m√©rete

        **Alkalmaz√°s:**
        - Kaotikus attraktorok √©s term√©szetes mint√°zatok (pl. felh≈ëk, erezetek) komplexit√°s√°nak m√©r√©se  
        - Neur√°lis aktivit√°s komplexit√°s√°nak jellemz√©se  
        - MRI √©s EEG adatok sk√°laf√ºggetlen szerkezeteinek felt√°r√°sa  

        **Jellemz≈ëk:**
        - A frakt√°ldimenzi√≥ lehet **nem eg√©sz sz√°m**, pl. Mandelbrot-halmaz: $D \\approx 1.26$  
        - A dimenzi√≥ n≈ë, ha az objektum egyre ink√°bb ‚Äûkit√∂lti‚Äù a teret.

        **Tudom√°nyos jelent≈ës√©g:**  
        A frakt√°ldimenzi√≥ seg√≠ts√©g√©vel **rendszerek komplexit√°sa** jellemezhet≈ë kvantitat√≠v m√≥don, k√ºl√∂n√∂sen ott, ahol klasszikus m√©rt√©kek (pl. topol√≥giai dimenzi√≥) cs≈ëd√∂t mondanak.
        """)

    with st.expander("üåã Criticality Explorer ‚Äì Neur√°lis rendszerek kritikus √°llapota"):
        st.latex(r"P(s) \propto s^{-\tau}")
        st.markdown("""
        **C√©l:** A neur√°lis rendszerek **√∂nszervez≈ëd≈ë kritikus viselked√©s√©nek** vizsg√°lata.  
        A kritikus pontokon megfigyelhet≈ë, hogy az aktivit√°seloszl√°s **sk√°laf√ºggetlen**, azaz **hatv√°nyf√ºggv√©ny** szerint alakul.

        **Magyar√°zat:**
        - $P(s)$: egy adott $s$ m√©ret≈± aktivit√°si esem√©ny val√≥sz√≠n≈±s√©ge  
        - $\\tau$: hatv√°nykitev≈ë (tipikusan $\\sim 1.5$ k√∂r√ºl)
 
        **Jellemz≈ëk:**
        - Nincs jellegzetes m√©ret: **kis √©s nagy aktivit√°sok** is el≈ëfordulnak  
        - **Kritikus lejt≈ë** jelenik meg log-log sk√°l√°n  
        - A rendszer √©rz√©kenyen reag√°l a bemenetekre

        **Felhaszn√°l√°s:**
        - Agyi aktivit√°s hull√°mz√°sainak (avalanches) modellez√©se  
        - Kritikus √°llapotok keres√©se √©s jellemz√©se  
        - Komplex rendszerek stabilit√°s√°nak √©s tanul√©konys√°g√°nak optimaliz√°l√°sa

        **Megjegyz√©s:**  
        A kritikusit√°s k√∂zel√©ben a h√°l√≥zat **maxim√°lis inform√°ci√≥feldolgoz√°si kapacit√°ssal** m≈±k√∂dhet.
        """)

    with st.expander("üìâ Lyapunov Spectrum ‚Äì Kaotikus rendszerek stabilit√°sa"):
        st.latex(r"\lambda_i = \lim_{t \to \infty} \frac{1}{t} \ln \frac{||\delta x_i(t)||}{||\delta x_i(0)||}")
        st.markdown("""
        **C√©l:** A dinamikus rendszer stabilit√°s√°nak vizsg√°lata a Lyapunov-exponenseken kereszt√ºl.  

        **Magyar√°zat:**
        - $\lambda_i$: az $i$-edik Lyapunov-exponens  
        - $\delta x_i$: perturb√°ci√≥ az √°llapott√©rben  
        - A pozit√≠v $\lambda$ √©rt√©kek a rendszer **kaotikuss√°g√°ra** utalnak  
        - A negat√≠v √©rt√©kek stabilit√°st jeleznek, m√≠g a nulla semleges viselked√©st

        **Felhaszn√°l√°s:**
        - Kaotikus rendszerek detekt√°l√°sa  
        - Stabil/instabil viselked√©s felt√©rk√©pez√©se  
        - Lorenz-rendszer, R√∂ssler-attraktor, Kuramoto-h√°l√≥zatok vizsg√°lata  

        **Tudom√°nyos h√°tt√©r:**  
        A Lyapunov-spektrum a **nemline√°ris dinamika** egyik alapvet≈ë eszk√∂ze. A teljes spektrum jellemzi a rendszer entr√≥pi√°j√°t √©s predikt√°lhat√≥s√°g√°t:
        """)
        st.latex(r"h_{KS} = \sum_{\lambda_i > 0} \lambda_i \quad \text{(Kolmogorov‚ÄìSinai entr√≥pia)}")

    with st.expander("üåÄ Frakt√°l Explorer ‚Äì Kaotikus rendszerek"):
        st.latex(r"z_{n+1} = z_n^2 + c")
        st.markdown("""
        **C√©l:** Mandelbrot- √©s Julia-halmazok megjelen√≠t√©se.  
        **Felhaszn√°l√°s:**
        - Stabil √©s kaotikus z√≥n√°k felt√°r√°sa  
        - Nemline√°ris dinamika vizualiz√°l√°sa  
        """)

    with st.expander("üîÑ Echo State Network ‚Äì Id≈ësoros el≈ërejelz√©s"):
        st.latex(r"\mathbf{x}(t+1) = \tanh(W_{res} \cdot \mathbf{x}(t) + W_{in} \cdot \mathbf{u}(t))")
        st.latex(r"\hat{y}(t) = W_{out} \cdot \mathbf{x}(t)")
        st.markdown("""
        **C√©l:** Id≈ësoros el≈ërejelz√©s kis tan√≠t√°si k√∂lts√©ggel.  
        **Felhaszn√°l√°s:**
        - Komplex rendszerek predikci√≥ja  
        - Dinamikus mintafelismer√©s  
        """)

    with st.expander("üß© Generative Kuramoto ‚Äì Strukt√∫ra √©s dinamika"):
        st.markdown("""
        **C√©l:** Random gr√°f gener√°l√°sa √©s annak dinamikai szimul√°ci√≥ja.  
        **Felhaszn√°l√°s:**
        - Gr√°f topol√≥gia √©s szinkroniz√°ci√≥ kapcsolat√°nak felt√°r√°sa  
        """)

    with st.expander("üßÆ Graph Sync Analysis ‚Äì H√°l√≥zati stabilit√°s"):
        st.markdown("""
        **C√©l:** Szinkroniz√°ci√≥ er≈ëss√©ge √©s Laplace spektrum elemz√©se.  
        **Felhaszn√°l√°s:**
        - Stabilit√°s √©s h√°l√≥zatszerkezet √∂sszef√ºgg√©seinek felt√°r√°sa  
        """)

    with st.expander("üèîÔ∏è Persistent Homology ‚Äì Topol√≥giai adat√©rtelmez√©s"):
        st.markdown("""
        **C√©l:** Perzisztens topol√≥giai strukt√∫r√°k kisz≈±r√©se.  
        **Felhaszn√°l√°s:**
        - Zaj √©s val√≥di szerkezet megk√ºl√∂nb√∂ztet√©se  
        - G√©pi tanul√°si jellemz≈ëk gener√°l√°sa  
        """)

    st.markdown("""---  
    Verzi√≥: **2025.07**  
    K√©sz√≠tette: *ReflectAI fejleszt≈ëi √©s tudom√°nyos tan√°csad√≥k*  
    """)

# K√∂telez≈ë bel√©p√©si pont
app = run
