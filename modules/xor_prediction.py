import numpy as np
import matplotlib.pyplot as plt
import streamlit as st
import time
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split

def run():
    st.title("üîÅ XOR Prediction ‚Äì Tudom√°nyos Neur√°lis H√°l√≥zat Playground")

    st.markdown("""
    Ez a modul egy neur√°lis h√°l√≥zatot alkalmaz az **XOR logikai m≈±velet** megtanul√°s√°ra,  
    tudom√°nyosan valid√°lhat√≥ m√≥don: aktiv√°ci√≥k, solverek, architekt√∫ra √©s loss anal√≠zis mellett.
    """)

    # --- Adat gener√°l√°s ---
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([0, 1, 1, 0])
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

    # --- Felhaszn√°l√≥i be√°ll√≠t√°sok ---
    hidden_layer_size = st.slider("üîß Rejtett r√©teg m√©rete", 2, 20, 4)
    max_iter = st.slider("üîÅ Iter√°ci√≥k sz√°ma", 100, 2000, 500, step=100)
    activation = st.selectbox("üìä Aktiv√°ci√≥s f√ºggv√©ny", ["tanh", "relu", "logistic"])
    solver = st.selectbox("üß≤ Solver algoritmus", ["adam", "sgd", "lbfgs"])
    learning_rate_init = st.slider("üìà Tanul√°si r√°ta", 0.001, 1.0, 0.01, step=0.01)
    show_3d = st.checkbox("üåê 3D vizualiz√°ci√≥", value=True)

    # --- Modell betan√≠t√°sa ---
    model = MLPClassifier(
        hidden_layer_sizes=(hidden_layer_size,),
        activation=activation,
        solver=solver,
        learning_rate_init=learning_rate_init,
        max_iter=max_iter,
        random_state=42
    )

    start = time.time()
    model.fit(X_train, y_train)
    end = time.time()

    # --- Ki√©rt√©kel√©s ---
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    st.success(f"üåü Modell pontoss√°ga: {acc:.2f} | Tan√≠t√°s ideje: {end-start:.3f} m√°sodperc")

    # --- Loss g√∂rbe ---
    if hasattr(model, 'loss_curve_'):
        fig_loss, ax_loss = plt.subplots()
        ax_loss.plot(model.loss_curve_)
        ax_loss.set_xlabel("Iter√°ci√≥")
        ax_loss.set_ylabel("Vesztes√©g")
        ax_loss.set_title("üìâ Tanul√°si vesztes√©g")
        st.pyplot(fig_loss)

    # --- Konf√∫zi√≥s m√°trix ---
    fig_cm, ax_cm = plt.subplots()
    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax_cm)
    st.pyplot(fig_cm)

    # --- 3D d√∂nt√©si fel√ºlet ---
    if show_3d:
        xx, yy = np.meshgrid(np.linspace(0, 1, 100), np.linspace(0, 1, 100))
        zz = np.array([
            model.predict([[x, y]])[0] for x, y in zip(np.ravel(xx), np.ravel(yy))
        ]).reshape(xx.shape)

        fig = go.Figure(data=[
            go.Surface(z=zz, x=xx, y=yy, colorscale='Viridis', opacity=0.85)
        ])
        fig.update_layout(
            title="üß† D√∂nt√©si fel√ºlet ‚Äì tanult reprezent√°ci√≥",
            scene=dict(xaxis_title='X‚ÇÅ', yaxis_title='X‚ÇÇ', zaxis_title='Predikci√≥'),
            margin=dict(l=0, r=0, t=60, b=0)
        )
        st.plotly_chart(fig, use_container_width=True)

    # --- Rejtett r√©teg aktiv√°ci√≥k ---
    with st.expander("üß© Rejtett r√©teg neuronjainak aktiv√°ci√≥i"):
        if activation == "logistic":
            act_fn = lambda x: 1 / (1 + np.exp(-x))
        elif activation == "tanh":
            act_fn = np.tanh
        elif activation == "relu":
            act_fn = lambda x: np.maximum(0, x)
        else:
            act_fn = lambda x: x

        W1 = model.coefs_[0]
        b1 = model.intercepts_[0]
        hidden_outputs = act_fn(np.dot(X, W1) + b1)

        fig_hidden, ax_hidden = plt.subplots()
        im = ax_hidden.imshow(hidden_outputs, cmap='coolwarm', aspect='auto')
        ax_hidden.set_xticks(range(hidden_outputs.shape[1]))
        ax_hidden.set_yticks(range(X.shape[0]))
        ax_hidden.set_xlabel("Neuron index")
        ax_hidden.set_ylabel("Bemeneti minta index")
        ax_hidden.set_title("üîç Aktiv√°ci√≥k a rejtett r√©tegben")
        fig_hidden.colorbar(im)
        st.pyplot(fig_hidden)

    # --- Tudom√°nyos magyar√°zat ---
    with st.expander("üìò Matematikai h√°tt√©r"):
        st.markdown(r"""
        Az **XOR** (exclusive OR) probl√©ma egy nemline√°risan szepar√°lhat√≥ logikai m≈±velet:

        $$
        \text{XOR}(x_1, x_2) =
        \begin{cases}
        0, & \text{ha } x_1 = x_2 \\
        1, & \text{ha } x_1 \neq x_2
        \end{cases}
        $$

        Egyetlen r√©teg≈± perceptron nem k√©pes ezt megtanulni, mert a bemeneti t√©r nem szepar√°lhat√≥ egyetlen egyenes ment√©n.

        A tanul√°si modell egy **t√∂bbr√©teg≈± perceptron (MLP)**:
        $$
        \hat{y} = \sigma \left( W^{(2)} \cdot \sigma(W^{(1)}x + b^{(1)}) + b^{(2)} \right)
        $$

        Itt:
        - $\sigma$ az aktiv√°ci√≥s f√ºggv√©ny (pl. $\tanh$, $\text{ReLU}$)
        - $W^{(1)}, W^{(2)}$ a s√∫lym√°trixok
        - $b^{(1)}, b^{(2)}$ a bias vektorok

        A c√©lf√ºggv√©ny (pl. MSE):
        $$
        \mathcal{L} = \frac{1}{N} \sum_{i=1}^N \left(y_i - \hat{y}_i\right)^2
        $$

        A tanul√°s c√©lja: a vesztes√©g minimaliz√°l√°sa a teljes tan√≠t√≥k√©szleten.
        """)

# K√∂telez≈ë ReflectAI bel√©p√©si pont
app = run
