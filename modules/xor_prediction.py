import numpy as np
import matplotlib.pyplot as plt
import streamlit as st
import time
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split

def run():
    st.title("üîÅ XOR Prediction ‚Äì Scientific Neural Network Playground")
    st.markdown("""
    Ez a modul egy neur√°lis h√°l√≥zatot alkalmaz az XOR logikai m≈±velet megtanul√°s√°ra.  
    A modell be√°ll√≠t√°sai testreszabhat√≥k, √©s a teljes tanul√°si folyamat nyomon k√∂vethet≈ë vizu√°lisan is.
    """)

    # Dataset
    X = np.array([[0,0],[0,1],[1,0],[1,1]])
    y = np.array([0,1,1,0])
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

    # Be√°ll√≠t√°sok
    hidden_layer_size = st.slider("üîß Rejtett r√©teg m√©rete", 2, 20, 4)
    max_iter = st.slider("üîÅ Iter√°ci√≥k sz√°ma", 100, 2000, 500, step=100)
    activation = st.selectbox("üìê Aktiv√°ci√≥s f√ºggv√©ny", ["tanh", "relu", "logistic"])
    solver = st.selectbox("üßÆ Solver algoritmus", ["adam", "sgd", "lbfgs"])
    show_3d = st.checkbox("üåê 3D vizualiz√°ci√≥", value=True)

    # Modell betan√≠t√°sa
    model = MLPClassifier(
        hidden_layer_sizes=(hidden_layer_size,),
        activation=activation,
        solver=solver,
        max_iter=1,
        warm_start=True
    )

    losses = []
    progress = st.progress(0)
    status = st.empty()

    for i in range(max_iter):
        model.fit(X_train, y_train)
        losses.append(model.loss_)
        progress.progress((i+1)/max_iter)
        status.text(f"Iter√°ci√≥: {i+1}/{max_iter} | Loss: {model.loss_:.4f}")

    # El≈ërejelz√©s √©s √©rt√©kel√©s
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    st.success(f"üéØ Modell pontoss√°ga: {acc:.2f}")

    # Konf√∫zi√≥s m√°trix
    fig_cm, ax_cm = plt.subplots()
    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax_cm)
    st.pyplot(fig_cm)

    # Loss-g√∂rbe
    fig_loss, ax_loss = plt.subplots()
    ax_loss.plot(losses)
    ax_loss.set_xlabel("Iter√°ci√≥")
    ax_loss.set_ylabel("Loss")
    ax_loss.set_title("üìâ Loss-g√∂rbe")
    st.pyplot(fig_loss)

    # M≈±k√∂d√©smagyar√°zat
    with st.expander("‚ÑπÔ∏è M≈±k√∂d√©smagyar√°zat ‚Äì Hogyan tanulja meg a h√°l√≥zat az XOR-t?"):
        st.markdown("""
        Az XOR m≈±velet kimenete csak akkor igaz (1), ha a k√©t bemenet elt√©r≈ë:
        - `XOR(0,0) = 0`
        - `XOR(0,1) = 1`
        - `XOR(1,0) = 1`
        - `XOR(1,1) = 0`

        Ez **nem line√°risan sz√©tv√°laszthat√≥** probl√©ma, ez√©rt egyetlen r√©teg≈± perceptron nem el√©g.  
        A h√°l√≥zatod egy vagy t√∂bb **rejtett neuront** tartalmaz, amelyek k√ºl√∂nb√∂z≈ë s√∫lyokat √©s aktiv√°ci√≥kat tanulnak.

        ### üß† Mit csin√°l a neur√°lis h√°l√≥zat?
        - A bemeneti p√°rokhoz (X1, X2) **egy kimeneti √©rt√©ket j√≥sol** (0 vagy 1 k√∂z√∂tt).
        - A c√©l, hogy az el≈ërejelz√©s **min√©l k√∂zelebb legyen** a val√≥di √©rt√©khez.
        - A tanul√°si folyamat sor√°n a s√∫lyokat friss√≠tj√ºk, hogy **cs√∂kkenjen a hiba** (loss).

        ### üõ∞Ô∏è Mit l√°tunk a 3D √°br√°n?
        A 3D felsz√≠n azt mutatja, hogy a neur√°lis h√°l√≥zat **milyen val√≥sz√≠n≈±s√©ggel** j√≥sol 1-et a bemeneti t√©r egyes pontjaira.

        - A `Z` tengelyen a kimeneti val√≥sz√≠n≈±s√©g van (0-t√≥l 1-ig).
        - Ahol magas a felsz√≠n, ott a modell **1-re tippel**, ahol alacsony, ott **0-ra**.
        - A d√∂nt√©si hat√°rvonal (decision boundary) egy **√°tmenet a domb √©s v√∂lgy k√∂z√∂tt**.

        ### üîÑ Mi√©rt v√°ltozik az alak?
        A be√°ll√≠t√°said (rejtett r√©teg, aktiv√°ci√≥, solver stb.) befoly√°solj√°k a tanul√°st.  
        N√©h√°ny be√°ll√≠t√°s gyorsabban konverg√°l, m√°sok √©rz√©kenyebbek.

        Pr√≥b√°lkozz k√ºl√∂nb√∂z≈ë param√©terekkel, √©s figyeld, **hogyan alakul √°t a felsz√≠n**!
        """)

    # 3D vizualiz√°ci√≥
    if show_3d:
        xx, yy = np.meshgrid(np.linspace(0, 1, 100), np.linspace(0, 1, 100))
        zz = np.array([
            model.predict([[x, y]])[0] for x, y in zip(np.ravel(xx), np.ravel(yy))
        ]).reshape(xx.shape)

        fig = go.Figure(data=[
            go.Surface(
                z=zz,
                x=xx,
                y=yy,
                colorscale='Viridis',
                opacity=0.9,
                showscale=True,
                contours=dict(
                    x=dict(show=False),
                    y=dict(show=False),
                    z=dict(show=False)
                )
            )
        ])

        fig.update_layout(
            title="üß† XOR ‚Äì 3D Surface from Neural Network",
            scene=dict(
                xaxis=dict(title='X1'),
                yaxis=dict(title='X2'),
                zaxis=dict(title='Output', nticks=4, range=[0, 1])
            ),
            margin=dict(l=0, r=0, t=60, b=0)
        )

        st.plotly_chart(fig, use_container_width=True)

# K√∂telez≈ë ReflectAI kompatibilit√°s
app = run
