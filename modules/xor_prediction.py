import numpy as np
import matplotlib.pyplot as plt
import streamlit as st
import time
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split

def run():
    st.title("üîÅ XOR Prediction ‚Äì Scientific Neural Network Playground")
    st.markdown("""
    Ez a modul egy neur√°lis h√°l√≥zatot alkalmaz az XOR logikai m≈±velet megtanul√°s√°ra.  
    A modell be√°ll√≠t√°sai testreszabhat√≥k, √©s a teljes tanul√°si folyamat nyomon k√∂vethet≈ë vizu√°lisan is.
    """)

    # Dataset
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([0, 1, 1, 0])
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

    # Be√°ll√≠t√°sok
    hidden_layer_size = st.slider("üîß Rejtett r√©teg m√©rete", 2, 20, 4)
    max_iter = st.slider("üîÅ Iter√°ci√≥k sz√°ma", 100, 2000, 500, step=100)
    activation = st.selectbox("üìä Aktiv√°ci√≥s f√ºggv√©ny", ["tanh", "relu", "logistic"])
    solver = st.selectbox("üß≤ Solver algoritmus", ["adam", "sgd", "lbfgs"])
    show_3d = st.checkbox("üåê 3D vizualiz√°ci√≥", value=True)

    # Modell tan√≠t√°sa (tanul√°sk√©pes v√°ltozat)
    model = MLPClassifier(
        hidden_layer_sizes=(hidden_layer_size,),
        activation=activation,
        solver=solver,
        max_iter=max_iter,
        random_state=42
    )

    start = time.time()
    model.fit(X_train, y_train)
    end = time.time()

    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    st.success(f"üåü Modell pontoss√°ga: {acc:.2f} | Tan√≠t√°s ideje: {end-start:.3f} sec")

    # Loss-g√∂rbe megjelen√≠t√©se
    if hasattr(model, 'loss_curve_'):
        fig_loss, ax_loss = plt.subplots()
        ax_loss.plot(model.loss_curve_)
        ax_loss.set_xlabel("Iter√°ci√≥")
        ax_loss.set_ylabel("Loss")
        ax_loss.set_title("üìâ Loss-g√∂rbe")
        st.pyplot(fig_loss)

    # Konf√∫z√≥s m√°trix
    fig_cm, ax_cm = plt.subplots()
    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax_cm)
    st.pyplot(fig_cm)

    # 3D vizualiz√°ci√≥ (vizu√°lisan finomabb)
    if show_3d:
        xx, yy = np.meshgrid(np.linspace(0, 1, 100), np.linspace(0, 1, 100))
        zz = np.array([
            model.predict([[x, y]])[0] for x, y in zip(np.ravel(xx), np.ravel(yy))
        ]).reshape(xx.shape)

        fig = go.Figure(data=[
            go.Surface(
                z=zz,
                x=xx,
                y=yy,
                colorscale='Viridis',
                opacity=0.9,
                showscale=True,
                contours=dict(
                    x=dict(show=False),
                    y=dict(show=False),
                    z=dict(show=False)
                )
            )
        ])

        fig.update_layout(
            title="üß† XOR ‚Äì 3D Surface from Neural Network",
            scene=dict(
                xaxis=dict(title='X1'),
                yaxis=dict(title='X2'),
                zaxis=dict(title='Output', nticks=4, range=[0, 1])
            ),
            margin=dict(l=0, r=0, t=60, b=0)
        )

        st.plotly_chart(fig, use_container_width=True)

    # üìñ M≈±k√∂d√©smagyar√°zat
    with st.expander("üîé Hogyan m≈±k√∂dik?"):
        st.markdown("""
        - Az XOR probl√©ma kiz√°r√≥lag nemline√°ris m√≥dszerekkel tanulhat√≥ meg.
        - A modul egy `MLPClassifier`-t alkalmaz, mely visszaterjeszt√©ses tanul√°ssal dolgozik.
        - A rejtett r√©teg m√©rete, aktiv√°ci√≥ √©s solver testreszabhat√≥.
        - A tanul√°s eredm√©nye a loss-g√∂rb√©n √©s 3D predikci√≥s fel√ºleten is vizsg√°lhat√≥.
        """)
        
    with st.expander("üîé Hogyan m≈±k√∂dik? (B≈ëv√≠tett magyar√°zat)"):
        st.markdown("""
        Az **XOR (exclusive OR)** logikai m≈±velet egy klasszikus p√©lda a nemline√°ris probl√©m√°kra, amelyeket egyetlen r√©teg≈± perceptron nem tud megtanulni. Ez√©rt sz√ºks√©g van **t√∂bbr√©teg≈±, nemline√°ris neur√°lis h√°l√≥zatra**, mint p√©ld√°ul az `MLPClassifier`.

        #### üî¢ XOR M≈±k√∂d√©se:
        - `XOR(0, 0) = 0`
        - `XOR(0, 1) = 1`
        - `XOR(1, 0) = 1`
        - `XOR(1, 1) = 0`

        #### üß† Alkalmazott modell: `MLPClassifier` (Multi-Layer Perceptron)
        - **Rejtett r√©tegek**: A felhaszn√°l√≥ v√°laszthatja meg a rejtett r√©teg m√©ret√©t.
        - **Aktiv√°ci√≥s f√ºggv√©nyek**: `relu`, `tanh`, `logistic` ‚Äì ezek vezetik be a nemlinearit√°st.
        - **Tanul√°si algoritmus** (`solver`): `adam`, `sgd`, `lbfgs`
        - **Vesztes√©gf√ºggv√©ny** (`loss`) k√∂vet√©se √©s vizualiz√°ci√≥ja.

        #### üìä Mit jelen√≠t meg az alkalmaz√°s?
        - A **tanul√°s pontoss√°g√°t** (`accuracy`) a tesztadatokra.
        - Egy **konf√∫zi√≥s m√°trixot**, amely vizu√°lisan mutatja a helyes √©s t√©ves oszt√°lyoz√°sokat.
        - Egy **loss-g√∂rb√©t**, amely az iter√°ci√≥k sor√°n m√©rt tanul√°si hib√°t mutatja.
        - Egy **3D vizualiz√°ci√≥t**, amely megjelen√≠ti a h√°l√≥ √°ltal tanult d√∂nt√©si hat√°rt a bemeneti t√©rben.
    
        #### ‚öóÔ∏è Mi√©rt √©rdekes ez?
        Az XOR probl√©ma az egyik els≈ë bemutat√≥ p√©lda arra, hogy a neur√°lis h√°l√≥zatok k√©pesek **komplex, nemline√°ris viselked√©s tanul√°s√°ra**, ha megfelel≈ëen vannak param√©terezve. E modul lehet≈ëv√© teszi, hogy ezt a tanul√°st **interakt√≠van √©s tudom√°nyos m√≥don** figyeld meg √©s elemezd.
        """)
        
# K√∂telez≈ë ReflectAI kompatibilit√°s
app = run
