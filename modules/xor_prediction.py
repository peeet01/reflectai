import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
import plotly.graph_objects as go


def run():
    st.set_page_config(layout="wide")
    st.title("ğŸ”€ XOR PredikciÃ³ â€“ TÃ¶bbrÃ©tegÅ± Perceptron")

    # ğŸ§­ BevezetÃ©s
    st.markdown("""
    A **XOR** (kizÃ¡rÃ³ vagy) logikai mÅ±velet nemlineÃ¡risan szeparÃ¡lhatÃ³,
    ezÃ©rt **egyrÃ©tegÅ± perceptronnal nem megoldhatÃ³**.

    Azonban egy **tÃ¶bbrÃ©tegÅ± perceptron (MLP)**, legalÃ¡bb egy rejtett rÃ©teggel,
    kÃ©pes megtanulni az elvÃ¡rt kimeneteket.
    Ez a modul egy ilyen tanulÃ¡st modellez interaktÃ­v mÃ³don.
    """)

    # ğŸ›ï¸ ParamÃ©terek
    st.sidebar.header("ğŸšï¸ ParamÃ©terek")
    hidden_size = st.sidebar.slider("Rejtett rÃ©teg mÃ©rete", 2, 10, 4)
    learning_rate = st.sidebar.slider("TanulÃ¡si rÃ¡ta", 0.001, 0.1, 0.01, step=0.001)
    max_iter = st.sidebar.slider("Max iterÃ¡ciÃ³", 100, 2000, 500, step=100)
    solver = st.sidebar.selectbox("Solver", ["adam", "sgd", "lbfgs"])

    # ğŸ§± XOR adat
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([0, 1, 1, 0])

    # ğŸ§  HÃ¡lÃ³ tanÃ­tÃ¡sa
    model = MLPClassifier(hidden_layer_sizes=(hidden_size,),
                          learning_rate_init=learning_rate,
                          max_iter=max_iter,
                          solver=solver,
                          random_state=42)
    model.fit(X, y)
    preds = model.predict(X)
    acc = accuracy_score(y, preds)

    # ğŸ“‰ 2D dÃ¶ntÃ©si fÃ¼ggvÃ©ny
    st.subheader("ğŸ“ˆ DÃ¶ntÃ©si felÃ¼let (2D)")
    xx, yy = np.meshgrid(np.linspace(0, 1, 200), np.linspace(0, 1, 200))
    grid = np.c_[xx.ravel(), yy.ravel()]
    Z = model.predict(grid).reshape(xx.shape)
    plt.figure(figsize=(4, 4))
    plt.contourf(xx, yy, Z, alpha=0.3, cmap="RdBu")
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap="RdBu", edgecolor="k", s=100)
    plt.title(f"PontossÃ¡g: {acc * 100:.1f}%")
    st.pyplot(plt.gcf())

    # ğŸŒ 3D aktivÃ¡ciÃ³
    st.subheader("ğŸŒ Rejtett rÃ©teg aktivÃ¡ciÃ³ (3D)")
    act = model.predict_proba(grid)[:, 1].reshape(xx.shape)
    fig3d = go.Figure(data=[go.Surface(z=act, x=xx, y=yy, colorscale="Viridis")])
    fig3d.update_layout(
        scene=dict(
            xaxis_title="xâ‚",
            yaxis_title="xâ‚‚",
            zaxis_title="P(kimenet=1)",
            zaxis=dict(nticks=6, range=[0, 1])
        ),
        margin=dict(l=10, r=10, t=50, b=10),
        height=600)
    st.plotly_chart(fig3d, use_container_width=True)

    # ğŸ§© EredmÃ©ny
    st.subheader("ğŸ¯ EredmÃ©nyek")
    st.markdown(f"""
    - HÃ¡lÃ³ struktÃºrÃ¡ja: **Inputâ€“{hidden_size}â€“Output**  
    - Solver: **{solver}**  
    - TanulÃ¡si rÃ¡ta: **{learning_rate}**  
    - IterÃ¡ciÃ³: **{model.n_iter_} / {max_iter}**  
    - PontossÃ¡g: **{acc * 100:.2f}%**
    """)

    # ğŸ“ CSV export
    st.subheader("ğŸ’¾ SÃºlyok exportÃ¡lÃ¡sa CSV-ben")
    weights = np.hstack([coef.flatten() for coef in model.coefs_])
    df = pd.DataFrame(weights.reshape(1, -1), columns=[f"w{i}" for i in range(len(weights))])
    csv = df.to_csv(index=False).encode('utf-8')
    st.download_button("â¬‡ï¸ SÃºlyok letÃ¶ltÃ©se", data=csv, file_name="xor_weights.csv")

    # ğŸ“˜ TudomÃ¡nyos hÃ¡ttÃ©r
    st.markdown("### ğŸ“™ TudomÃ¡nyos hÃ¡ttÃ©r â€“ Matematikai mÃ©lysÃ©g")

    st.latex(r"""
    y = \begin{cases}
        1 & \text{ha } x_1 \oplus x_2 = 1,\\
        0 & \text{kÃ¼lÃ¶nben}
    \end{cases}
    """)
    st.latex(r"""
    f(x) = \sigma\left(W^{(2)}\,\sigma(W^{(1)}x + b^{(1)}) + b^{(2)}\right)
    """)
    st.latex(r"""
    L = -\frac{1}{N} \sum_{i=1}^N \left[y_i\log \hat{y}_i + (1 - y_i)\log(1 - \hat{y}_i)\right]
    """)
    st.latex(r"""
    \frac{\partial L}{\partial W^{(l)}} = \delta^{(l)} a^{(l-1)^T}
    """)
    st.latex(r"""
    \sigma(x) = \frac{1}{1 + e^{-x}}, \quad \sigma'(x) = \sigma(x)(1 - \sigma(x))
    """)

    st.markdown("""
    - **XOR problÃ©ma** nem oldhatÃ³ meg lineÃ¡ris dÃ¶ntÃ©si hatÃ¡rral.
    - A megoldÃ¡s kulcsa a **nemlineÃ¡ris aktivÃ¡ciÃ³** (pl. sigmoid, tanh, ReLU).
    - A **visszaterjesztÃ©s** algoritmus kiszÃ¡mÃ­tja a sÃºlyfrissÃ­tÃ©seket a gradiens alapjÃ¡n.

    #### GradiensalapÃº tanulÃ¡s:
    A cÃ©lfÃ¼ggvÃ©ny gradiensÃ©nek szÃ¡mÃ­tÃ¡sa lehetÅ‘vÃ© teszi a sÃºlyok optimalizÃ¡lÃ¡sÃ¡t:

    \( \frac{\partial L}{\partial W} \rightarrow \text{sÃºlyfrissÃ­tÃ©s: } W := W - \eta \frac{\partial L}{\partial W} \)

    #### KonklÃºziÃ³:
    A tÃ¶bbrÃ©tegÅ± perceptron kis mÃ©retÅ± rejtett rÃ©teggel is kÃ©pes megtanulni a XOR logikai feladatot, feltÃ©ve, hogy van:
    - elegendÅ‘ iterÃ¡ciÃ³,
    - megfelelÅ‘ tanulÃ¡si rÃ¡ta,
    - Ã©s nemlineÃ¡ris aktivÃ¡ciÃ³s fÃ¼ggvÃ©ny.
    """)


# ReflectAI kompatibilitÃ¡s
app = run
