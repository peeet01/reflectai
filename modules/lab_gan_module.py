import streamlit as st
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torchvision.utils import make_grid
import matplotlib.pyplot as plt
import pandas as pd

# --- Modell oszt√°lyok ---
class Generator(nn.Module):
    def __init__(self, z_dim=64, img_dim=28 * 28):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(z_dim, 256),
            nn.ReLU(True),
            nn.Linear(256, 512),
            nn.ReLU(True),
            nn.Linear(512, img_dim),
            nn.Tanh()
        )

    def forward(self, x):
        return self.net(x)


class Discriminator(nn.Module):
    def __init__(self, img_dim=28 * 28):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(img_dim, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.net(x)

# --- K√©pgener√°l√°s megjelen√≠t√©se ---
def show_generated_images(generator, z_dim, device):
    generator.eval()
    with torch.no_grad():
        z = torch.randn(16, z_dim).to(device)
        fake_imgs = generator(z).view(-1, 1, 28, 28).cpu()
        grid = make_grid(fake_imgs, nrow=4, normalize=True)
        fig, ax = plt.subplots(figsize=(4, 4))
        ax.imshow(grid.permute(1, 2, 0))
        ax.axis("off")
        st.pyplot(fig)


def run():
    st.set_page_config(layout="wide")
    st.title("üß™ GAN ‚Äì Generative Adversarial Network")

    st.markdown("""
    A Generative Adversarial Network (GAN) k√©t modellb≈ël √°ll:

    - **Gener√°tor**: √∫j adatminta gener√°l√°sa a zajb√≥l
    - **Diszkrimin√°tor**: eld√∂nti, hogy a bemen≈ë k√©p val√≥di vagy hamis

    $$ \\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))] $$
    """)

    device = "cuda" if torch.cuda.is_available() else "cpu"

    # --- Oldals√°v ---
    with st.sidebar:
        st.header("‚öôÔ∏è Be√°ll√≠t√°sok")
        z_dim = st.slider("Z dimenzi√≥", 32, 128, 64, step=16)
        lr = st.select_slider("Tanul√°si r√°ta", options=[1e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3], value=2e-4)
        epochs = st.slider("Epochok sz√°ma", 1, 20, 5)
        batch_size = st.slider("Batch m√©ret", 16, 128, 32, step=16)
        seed = st.number_input("Seed", 0, 9999, 42)

    if st.button("üöÄ Tan√≠t√°s ind√≠t√°sa"):
        torch.manual_seed(seed)

        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))
        ])
        dataset = datasets.MNIST(root="./data", train=True, download=True, transform=transform)
        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

        generator = Generator(z_dim).to(device)
        discriminator = Discriminator().to(device)
        optim_g = optim.Adam(generator.parameters(), lr=lr)
        optim_d = optim.Adam(discriminator.parameters(), lr=lr)
        criterion = nn.BCELoss()

        g_losses, d_losses = [], []
        progress = st.progress(0.0, text="Tan√≠t√°s folyamatban...")

        for epoch in range(epochs):
            for real_imgs, _ in loader:
                real_imgs = real_imgs.view(-1, 28 * 28).to(device)
                batch = real_imgs.size(0)
                real = torch.ones(batch, 1).to(device)
                fake = torch.zeros(batch, 1).to(device)

                # Diszkrimin√°tor tan√≠t√°sa
                z = torch.randn(batch, z_dim).to(device)
                fake_imgs = generator(z)
                loss_real = criterion(discriminator(real_imgs), real)
                loss_fake = criterion(discriminator(fake_imgs.detach()), fake)
                loss_d = (loss_real + loss_fake) / 2
                optim_d.zero_grad()
                loss_d.backward()
                optim_d.step()

                # Gener√°tor tan√≠t√°sa
                z = torch.randn(batch, z_dim).to(device)
                fake_imgs = generator(z)
                loss_g = criterion(discriminator(fake_imgs), real)
                optim_g.zero_grad()
                loss_g.backward()
                optim_g.step()

            g_losses.append(loss_g.item())
            d_losses.append(loss_d.item())
            st.markdown(f"üìä **Epoch {epoch+1}/{epochs}** | Generator: {loss_g.item():.4f} | Diszkrimin√°tor: {loss_d.item():.4f}")
            progress.progress((epoch + 1) / epochs)

        # --- Loss √°bra ---
        st.subheader("üìâ Loss alakul√°sa")
        fig, ax = plt.subplots()
        ax.plot(g_losses, label="Gener√°tor")
        ax.plot(d_losses, label="Diszkrimin√°tor")
        ax.set_xlabel("Epoch")
        ax.set_ylabel("Loss √©rt√©k")
        ax.legend()
        st.pyplot(fig)

        # --- Mint√°k megjelen√≠t√©se ---
        st.subheader("üñºÔ∏è Gener√°lt mint√°k")
        show_generated_images(generator, z_dim, device)

        # --- CSV ment√©s ---
        z = torch.randn(100, z_dim).to(device)
        samples = generator(z).view(-1, 28 * 28).cpu().detach().numpy()
        df = pd.DataFrame(samples)
        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button("‚¨áÔ∏è Mint√°k let√∂lt√©se (CSV)", data=csv, file_name="gan_samples.csv")

        # --- Tudom√°nyos √©rt√©kel√©s ---
        st.subheader("üß† Tudom√°nyos √©rt√©kel√©s")
        st.markdown("""
        A gener√°tor √©s diszkrimin√°tor vesztes√©g√©rt√©kei alapj√°n j√≥l k√∂vethet≈ë a tanul√°si dinamika. A diszkrimin√°tor kezdetben hat√©konyan k√ºl√∂nb√∂zteti meg a hamis k√©peket, de a gener√°tor id≈ëvel javul, √©s egyre jobban k√©pes megt√©veszteni azt.

        A h√°l√≥zat a minimax c√©lf√ºggv√©ny alapj√°n optimaliz√°lja mag√°t, melyet az al√°bbi k√©plettel jellemezhet√ºnk:

        $$ \\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))] $$

        A tov√°bbi tan√≠t√°s (nagyobb epochs sz√°m) seg√≠theti a gener√°lt k√©pek min≈ës√©g√©nek javul√°s√°t.
        """)

# App v√©grehajt√°s
app = run
