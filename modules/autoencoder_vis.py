import streamlit as st
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torchvision.utils import make_grid
import matplotlib.pyplot as plt
import pandas as pd
import plotly.express as px

# ----- Adatok bet√∂lt√©se -----
transform = transforms.ToTensor()
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=True, download=True, transform=transform),
    batch_size=128, shuffle=True
)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=False, transform=transform),
    batch_size=1000, shuffle=False
)

# ----- Autoencoder modell -----
class Autoencoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28 * 28, 128),
            nn.ReLU(),
            nn.Linear(128, 3)
        )
        self.decoder = nn.Sequential(
            nn.Linear(3, 128),
            nn.ReLU(),
            nn.Linear(128, 28 * 28),
            nn.Sigmoid()
        )

    def forward(self, x):
        z = self.encoder(x)
        x_recon = self.decoder(z)
        return x_recon

# ----- App -----
def app():
    st.set_page_config(layout="wide")
    st.title("üß† Autoencoder Vizualiz√°ci√≥ ‚Äì 3D Latens t√©r")

    with st.expander("üìò Mi t√∂rt√©nik ebben a modulban?", expanded=True):
        st.markdown("""
        Egy **autoencoder** c√©lja, hogy a bemeneti adatot **egy alacsony dimenzi√≥s t√©rbe lek√©pezze**, majd onnan vissza√°ll√≠tsa azt.  
        A k√∂z√©ps≈ë 3-dimenzi√≥s k√≥dolt reprezent√°ci√≥ seg√≠ts√©g√©vel **vizualiz√°lni tudjuk az adatokat**.

        #### üß† Alapstrukt√∫ra:
        - **Encoder**: $x \\rightarrow z$
        - **Decoder**: $z \\rightarrow \\hat{x}$

        #### üí° C√©lf√ºggv√©ny:
        A modell c√©lja, hogy minimaliz√°lja a rekonstrukci√≥s hib√°t:

        $$
        \\mathcal{L} = \\frac{1}{N} \\sum_i \\| x_i - \\hat{x}_i \\|^2
        $$

        Ahol:
        - $x_i$: eredeti k√©p
        - $\\hat{x}_i$: rekonstru√°lt k√©p
        - $z$: latens reprezent√°ci√≥

        A 3D latens t√©r lehet≈ëv√© teszi, hogy a **k√©pek kateg√≥ri√°i k√ºl√∂n klaszterekk√©nt** jelenjenek meg.

        """)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = Autoencoder().to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-3)

    if st.button("üöÄ Tan√≠t√°s ind√≠t√°sa (12 epoch)"):
        loss_history = []

        for epoch in range(12):
            model.train()
            total_loss = 0
            for data, _ in train_loader:
                data = data.to(device)
                optimizer.zero_grad()
                output = model(data)
                loss = criterion(output, data.view(-1, 28*28))
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            avg_loss = total_loss / len(train_loader)
            loss_history.append(avg_loss)
            st.write(f"üìä Epoch {epoch+1}/12 | Loss: {avg_loss:.4f}")

        # Loss g√∂rbe
        st.subheader("üìâ Rekonstrukci√≥s hiba alakul√°sa")
        fig, ax = plt.subplots()
        ax.plot(loss_history)
        ax.set_xlabel("Epoch")
        ax.set_ylabel("Loss")
        ax.set_title("Rekonstrukci√≥s hiba")
        st.pyplot(fig)

        # K√©pek rekonstru√°l√°sa
        st.subheader("üñºÔ∏è Rekonstru√°lt k√©pek")
        model.eval()
        with torch.no_grad():
            test_imgs, test_labels = next(iter(test_loader))
            test_imgs = test_imgs.to(device)
            encoded = model.encoder(test_imgs)
            decoded = model.decoder(encoded).view(-1, 1, 28, 28).cpu()

        grid = make_grid(decoded[:10], nrow=5, normalize=True)
        st.image(grid.permute(1, 2, 0).numpy(), clamp=True)

        # 3D Plotly scatter
        st.subheader("üåå 3D Latens t√©r (Plotly)")
        z = encoded.cpu().numpy()
        labels = test_labels.numpy()
        df = pd.DataFrame(z, columns=["x", "y", "z"])
        df["label"] = labels
        fig = px.scatter_3d(df, x="x", y="y", z="z", color=df["label"].astype(str),
                            title="MNIST latens reprezent√°ci√≥", width=800, height=600)
        st.plotly_chart(fig)

        # Tudom√°nyos √©rt√©kel√©s
        st.subheader("üß™ Tudom√°nyos √©rt√©kel√©s")
        st.markdown("""
        Az autoencoder sikeresen lek√©pezte az MNIST sz√°mjegyeket egy **3D latens t√©rbe**, ahol az egyes oszt√°lyok l√°that√≥an klaszterez≈ëdnek.

        Ez azt mutatja, hogy a modell k√©pes **kompakt reprezent√°ci√≥kat** kialak√≠tani, amelyek **meg≈ërzik a kateg√≥ria-inform√°ci√≥t**.

        #### üî¨ K√∂vetkeztet√©s:
        - A k√≥dolt t√©r **szerkezetet t√ºkr√∂z**, nem v√©letlenszer≈±
        - Alkalmazhat√≥ **dimenzi√≥cs√∂kkent√©sre**, **adatvizualiz√°ci√≥ra** √©s **el≈ëfeldolgoz√°sra**
        """)

# ReflectAI-kompatibilis
app = app
