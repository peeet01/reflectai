import streamlit as st
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torchvision.utils import make_grid
import matplotlib.pyplot as plt

# --- Egyszer≈± Autoencoder ---
class Autoencoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(28*28, 128),
            nn.ReLU(),
            nn.Linear(128, 32),
            nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.Linear(32, 128),
            nn.ReLU(),
            nn.Linear(128, 28*28),
            nn.Tanh()
        )

    def forward(self, x):
        z = self.encoder(x)
        return self.decoder(z)

def plot_reconstruction(model, device):
    model.eval()
    with torch.no_grad():
        sample = next(iter(DataLoader(
            datasets.MNIST('./data', train=False, download=True,
                           transform=transforms.ToTensor()),
            batch_size=8
        )))[0].to(device)
        original = sample.view(-1, 28*28)
        reconstructed = model(original).view(-1, 1, 28, 28).cpu()
        grid = make_grid(reconstructed, nrow=4, normalize=True)
        fig, ax = plt.subplots()
        ax.imshow(grid.permute(1, 2, 0))
        ax.axis("off")
        st.pyplot(fig)

# --- Streamlit modul ---
def run():
    st.set_page_config(layout="wide")
    st.title("üß† Autoencoder ‚Äì Dimenzi√≥cs√∂kkent√©s √©s rekonstrukci√≥")

    st.markdown("""
    Az **autoencoder** egy neur√°lis h√°l√≥, amely megtanulja **t√∂m√∂r√≠teni** a bemeneti adatot √©s ut√°na **rekonstru√°lni** azt.  
    C√©lja, hogy a t√∂m√∂r√≠tett reprezent√°ci√≥ (k√≥d) elegend≈ë inform√°ci√≥t tartalmazzon a bemenet vissza√°ll√≠t√°s√°hoz.

    - Encoder: bemeneti adat ‚Üí t√∂m√∂r√≠tett reprezent√°ci√≥  
    - Decoder: reprezent√°ci√≥ ‚Üí rekonstrukci√≥

    Hasznos **dimenzi√≥cs√∂kkent√©sre**, **zajsz≈±r√©sre** √©s **adatfelt√°r√°sra**.
    """)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    epochs = st.sidebar.slider("Epochok sz√°ma", 1, 20, 5)
    lr = st.sidebar.select_slider("Tanul√°si r√°ta", [1e-4, 5e-4, 1e-3], value=1e-3)
    batch_size = st.sidebar.slider("Batch m√©ret", 32, 256, 128, step=32)

    if st.button("üîÅ Autoencoder tan√≠t√°sa"):
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))
        ])
        dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

        model = Autoencoder().to(device)
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=lr)

        for epoch in range(epochs):
            total_loss = 0
            for imgs, _ in loader:
                imgs = imgs.view(-1, 28*28).to(device)
                outputs = model(imgs)
                loss = criterion(outputs, imgs)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            st.write(f"üìä Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(loader):.4f}")

        st.subheader("üîç Rekonstru√°lt k√©pek")
        plot_reconstruction(model, device)

# ReflectAI-kompatibilit√°s
app = run
