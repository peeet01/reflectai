import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import plotly.graph_objects as go

# üîÅ Hebbian tanul√°si algoritmus
def hebbian_learning(X, T, eta, epochs):
    weights = np.zeros(X.shape[1])
    history = []
    for _ in range(epochs):
        for x, t in zip(X, T):
            weights += eta * x * t
            history.append(weights.copy())
    return np.array(history)

# üéØ Bemeneti adatok (AND logika)
def generate_inputs():
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    T = np.array([0, 0, 0, 1])
    return X, T

# üöÄ Streamlit app
def run():
    st.title("üß† Hebbian Learning ‚Äì Egyszer≈± szinaptikus tanul√°s")

    st.markdown("""
    A Hebbian tanul√°s egy alapvet≈ë tanul√°si szab√°ly, amely az agyban zajl√≥ **szinaptikus plaszticit√°st** modellezi.  
    A tanul√°si folyamat sor√°n a s√∫lyok m√≥dosul√°sa att√≥l f√ºgg, hogy a bemenet √©s a kimenet **egyszerre aktiv√°l√≥dik-e**.
    """)

    st.subheader("üîß Param√©terek")
    eta = st.slider("Tanul√°si r√°ta (Œ∑)", 0.01, 1.0, 0.1, step=0.01)
    epochs = st.slider("Epoch-ok sz√°ma", 1, 100, 20)

    X, T = generate_inputs()
    history = hebbian_learning(X, T, eta, epochs)

    # üìà 2D s√∫lyv√°ltoz√°s
    st.subheader("üìâ S√∫lyv√°ltoz√°sok id≈ëben (2D)")
    fig, ax = plt.subplots()
    ax.plot(history[:, 0], label="w‚ÇÄ", linewidth=2)
    ax.plot(history[:, 1], label="w‚ÇÅ", linewidth=2)
    ax.set_xlabel("Iter√°ci√≥")
    ax.set_ylabel("S√∫ly √©rt√©k")
    ax.set_title("Hebbian tanul√°s s√∫lydinamik√°ja")
    ax.legend()
    st.pyplot(fig)

    # üåê 3D vizualiz√°ci√≥
    st.subheader("üåê S√∫lyp√°lya 3D t√©rben")
    fig3d = go.Figure(data=[go.Scatter3d(
        x=history[:, 0],
        y=history[:, 1],
        z=np.arange(len(history)),
        mode='lines+markers',
        marker=dict(size=4, color=np.arange(len(history)), colorscale='Viridis'),
        line=dict(width=3, color='darkblue')
    )])
    fig3d.update_layout(scene=dict(
        xaxis_title="w‚ÇÄ",
        yaxis_title="w‚ÇÅ",
        zaxis_title="Iter√°ci√≥"
    ), margin=dict(l=0, r=0, t=30, b=0), height=500)
    st.plotly_chart(fig3d, use_container_width=True)

    # üì• CSV export
    st.subheader("üíæ Eredm√©nyek export√°l√°sa")
    df = pd.DataFrame(history, columns=["w‚ÇÄ", "w‚ÇÅ"])
    csv = df.to_csv(index_label="iter√°ci√≥").encode("utf-8")
    st.download_button("‚¨áÔ∏è S√∫lyok let√∂lt√©se CSV-ben", data=csv, file_name="hebb_weights.csv")

    # üìö Tudom√°nyos h√°tt√©r
    st.markdown("### üìö Tudom√°nyos h√°tt√©r")
    st.markdown(r"""
A **Hebbian tanul√°s** az egyik legegyszer≈±bb tanul√°si szab√°ly,  
amely a biol√≥giai neuronh√°l√≥k **szinaptikus er≈ës√∂d√©s√©t** modellezi.

#### üß† Alapelv:
> *‚ÄûAzok a neuronok, amelyek egy√ºtt t√ºzelnek, egy√ºtt huzaloz√≥dnak.‚Äù*

#### üìê S√∫lyfriss√≠t√©si k√©plet:

$$
w_i \leftarrow w_i + \eta \cdot x_i \cdot t
$$

**Ahol:**

- \( w_i \): az *i*-edik bemeneti s√∫ly  
- \( \eta \): tanul√°si r√°ta  
- \( x_i \): a bemeneti neuron aktiv√°ci√≥ja  
- \( t \): a kimeneti neuron aktiv√°ci√≥ja (vagy c√©l√©rt√©k)

Ez a szab√°ly akkor m√≥dos√≠tja a s√∫lyokat, ha a bemenet √©s kimenet **egy√ºtt aktiv√°l√≥dik**, vagyis korrel√°lnak.  
A Hebbian-elv alapvet≈ë szerepet j√°tszik a **nem fel√ºgyelt tanul√°s** modellez√©s√©ben, √©s megalapozza az asszociat√≠v mem√≥ri√°k m≈±k√∂d√©s√©t.

#### üìå Alkalmaz√°s:
- Biol√≥giai tanul√°si mechanizmusok szimul√°ci√≥ja  
- Nem fel√ºgyelt neur√°lis modellek alapja  
- Szinaptikus er≈ëss√©gek id≈ëbeli v√°ltoz√°s√°nak meg√©rt√©se
""")

# ‚úÖ ReflectAI kompatibilit√°s
app = run
