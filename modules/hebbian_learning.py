import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
import plotly.graph_objects as go

def hebbian_learning(X, T, eta, epochs):
    weights = np.zeros(X.shape[1])
    history = []

    for _ in range(epochs):
        for x, t in zip(X, T):
            weights += eta * x * t
            history.append(weights.copy())

    return np.array(history)

def generate_inputs():
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    T = np.array([0, 0, 0, 1])  # AND logikai mÅ±velet
    return X, T

def main():
    st.title("ğŸ§  Hebbian Learning SzimulÃ¡ciÃ³")
    st.markdown("Fedezd fel a Hebb-szabÃ¡ly mÅ±kÃ¶dÃ©sÃ©t egy egyszerÅ± pÃ©ldÃ¡n keresztÃ¼l.")

    eta = st.slider("TanulÃ¡si rÃ¡ta (Î·)", 0.01, 1.0, 0.1, step=0.01)
    epochs = st.slider("Epoch-ok szÃ¡ma", 1, 100, 20)

    X, T = generate_inputs()
    history = hebbian_learning(X, T, eta, epochs)

    # 2D plot
    st.subheader("ğŸ“ˆ SÃºlyvÃ¡ltozÃ¡sok 2D-ben")
    fig, ax = plt.subplots()
    ax.plot(history[:, 0], label="wâ‚€")
    ax.plot(history[:, 1], label="wâ‚")
    ax.set_xlabel("IterÃ¡ciÃ³")
    ax.set_ylabel("SÃºly Ã©rtÃ©k")
    ax.set_title("Hebbian sÃºlytanulÃ¡s")
    ax.legend()
    st.pyplot(fig)

    # 3D plot
    st.subheader("ğŸ“Š SÃºlypÃ¡lya vizualizÃ¡ciÃ³ 3D-ben")
    fig3d = go.Figure(data=[go.Scatter3d(
        x=history[:, 0],
        y=history[:, 1],
        z=np.arange(len(history)),
        mode='lines+markers',
        marker=dict(size=4),
        line=dict(width=2)
    )])
    fig3d.update_layout(scene=dict(
        xaxis_title="wâ‚€",
        yaxis_title="wâ‚",
        zaxis_title="IterÃ¡ciÃ³"
    ), margin=dict(l=0, r=0, b=0, t=30), height=500)
    st.plotly_chart(fig3d)

    # CSV export
    st.subheader("ğŸ“¥ Export")
    df = pd.DataFrame(history, columns=["wâ‚€", "wâ‚"])
    csv = df.to_csv(index_label="iterÃ¡ciÃ³").encode("utf-8")
    st.download_button("SÃºlyok letÃ¶ltÃ©se CSV-ben", data=csv, file_name="hebb_weights.csv")

    # TudomÃ¡nyos hÃ¡ttÃ©r
    st.markdown("### ğŸ“š TudomÃ¡nyos hÃ¡ttÃ©r")
    st.markdown(r"""
> *"A neuronok, amelyek egyÃ¼tt tÃ¼zelnek, egyÃ¼tt huzalozÃ³dnak."*

Matematikailag a Hebb-szabÃ¡ly Ã­gy Ã­rhatÃ³ fel:

\[
w_i \leftarrow w_i + \eta \cdot x_i \cdot t
\]

ahol:

- î€w_iî€: az î€iî€-edik bemenethez tartozÃ³ sÃºly  
- î€\etaî€: tanulÃ¡si rÃ¡ta  
- î€x_iî€: bemenet aktuÃ¡lis Ã©rtÃ©ke  
- î€tî€: a cÃ©lÃ©rtÃ©k (posztszinaptikus aktivitÃ¡s)

Ez a szabÃ¡ly a szinaptikus erÅ‘ssÃ©gek vÃ¡ltozÃ¡sÃ¡t modellezi az alapjÃ¡n, hogy a bemeneti Ã©s kimeneti neuronok **egyszerre aktivÃ¡lÃ³dnak-e**.  
A Hebbian tanulÃ¡s **nem igÃ©nyel hibavisszacsatolÃ¡st**, Ã©s jÃ³l modellezi az agykÃ©reg szinaptikus plaszticitÃ¡sÃ¡t.
""")

# App indÃ­tÃ³
if __name__ == "__main__":
    main()
